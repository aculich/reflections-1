reflections
===========

This week, like most weeks, was definitely a frustrating week in this course. Most of it is centered around the bureaucracy of the course.

Understand, I spent the summer learning the hard way that people should not simply start coding before jumping into code. Doing so is a massive waste of time. An ounce of good planning is worth more than a metric ton of bad code. I am much more patient about doing teambuilding before "doing real work" than most of my colleagues are. God and men have seen what happens when people jump into things without plotting everything out first.

All of this said, we shouldn't be seven weeks in, getting assigned roles and teams twice, and only then being given a project. The project is also well out-of-scope for the majority of teams, at least in Python. The instructors have probably underestimated how unfamiliar the students are with coding, not just Python. Yes, I was able to do the first third of the coding in about an hour for my teammate, but that's because I'm unusual in having a (relatively) extensive coding background. My teammate spent upwards of 8 hours banging her head against a wall failing to do it without my help. In summary, we essentially accomplished nothing for six weeks, and suddenly we're rushing to fill the void in the course of a few days.

Also, kudos to Professor Stark. He really put his heart into presenting, and he did a fairly good job. But what a tough audience! I found his jokes funny, but the room was always silent for each one! It must have been really awful. Before beginning criticisms, I do want to note that he's easily in my top 5 Berkeley lecturers after 4 years.

That said, the whole lecture, I kept asking myself, "Am I learning anything about reproducibility, collaboration, or data science?" And each time, the answer was basically no. We talked about some statistical modeling and seismology, but without looking at any of the data, I feel that it was highly pedagogical and not at all hands-on to basically just be talking about, frankly, chance theory. What is probability? Important question, maybe, but when we still haven't learned what the process for doing data science even looks like, criticisms of the process are extraneous. On a similar vein, why are we studying a very specific subproblem of data science (seismology) that we're ill-equiped to handle, rather than starting with the basics of how one goes about data science. Also, the email exchange, while informative, did smell slightly of trumpeting Stark's personal conflicts that we really didn't need to go into too deeply.

Still, I'm glad that the project is coming along
